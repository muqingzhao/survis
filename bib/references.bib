
@article{1,
  author       = {Radoslaw Miernik and
                  Jakub Kowalski},
  title        = {Evolving Evaluation Functions for Collectible Card Game {AI}},
  journal      = {CoRR},
  volume       = {abs/2105.01115},
  year         = {2021},
  keywords     = {Evolutionary Algorithms, Evaluation Functions, 
Collectible Card Games, Genetic Programming, Strategy Card Game AI Competition, Legends of Code and Magic, card games, Artificial intelligence},
  url          = {https://arxiv.org/abs/2105.01115},
  eprinttype   = {arXiv},
  eprint       = {2105.01115},
  timestamp    = {Wed, 12 May 2021 15:54:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2105-01115.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
 
}

@INPROCEEDINGS{9961110,
  author={Vieira, Ronaldoe Silva and Tavares, Anderson Rocha and Chaimowicz, Luiz},
  booktitle={2022 21st Brazilian Symposium on Computer Games and Digital Entertainment (SBGames)}, 
  title={Exploring Deep Reinforcement Learning for Battling in Collectible Card Games}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/SBGAMES56371.2022.9961110},
  keywords={collectible card games, reinforcement learning, Artificial intelligence, card games, Q-learning algorithm}
}

@INPROCEEDINGS{9291616,
  author={Vieira, Ronaldo and Tavares, Anderson Rocha and Chaimowicz, Luiz},
  booktitle={2020 19th Brazilian Symposium on Computer Games and Digital Entertainment (SBGames)}, 
  title={Drafting in Collectible Card Games via Reinforcement Learning}, 
  year={2020},
  volume={},
  number={},
  pages={54-61},
  doi={10.1109/SBGames51465.2020.00018},
  keywords={collectible card games, deck building, reinforcement learning, card games, DRL algorithm}}

@inproceedings{5,
author = {Liu, Tianyu and Zheng, Zijie and Li, Hongchang and Bian, Kaigui and Song, Lingyang},
title = {Playing Card-Based RTS Games with Deep Reinforcement Learning},
year = {2019},
isbn = {9780999241141},
publisher = {AAAI Press},
abstract = {Game AI is of great importance as games are simulations of reality. Recent research on game AI has shown much progress in various kinds of games, such as console games, board games and MOBA games. However, the exploration in RTS games remains a challenge for their huge state space, imperfect information, sparse rewards and various strategies. Besides, the typical card-based RTS games have complex card features and are still lacking solutions. We present a deep model SEAT (selection-attention) to play card-based RTS games. The SEAT model includes two parts, a selection part for card choice and an attention part for card usage, and it learns from scratch via deep reinforcement learning. Comprehensive experiments are performed on Clash Royale, a popular mobile card-based RTS game. Empirical results show that the SEAT model agent makes it to reach a high winning rate against rule-based agents and decision-tree-based agent.},
booktitle = {Proceedings of the 28th International Joint Conference on Artificial Intelligence},
pages = {4540–4546},
numpages = {7},
location = {Macao, China},
series = {IJCAI'19},
keywords = {deep learning, AI, SEAT, selection attention, RTS game, Board Games, Artificial intelligence, SEAT  algorithm}
}

@INPROCEEDINGS{9893668,
  author={Gaina, Raluca D. and Balla, Martin},
  booktitle={2022 IEEE Conference on Games (CoG)}, 
  title={TAG: Pandemic Competition}, 
  year={2022},
  volume={},
  number={},
  pages={552-559},
  doi={10.1109/CoG51982.2022.9893668},
  keywords = {Tabletop Games, Board Games, Pandemic, General Game Playing, Monte Carlo Tree Search, Game Analytics, MAP-Elites, N-Tuple Bandit Evolutionary Algorithm }}

@inproceedings{4,
author = {Johansson, Stefan J.},
title = {On Using Multi-Agent Systems in Playing Board Games},
year = {2006},
isbn = {1595933034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1160633.1160737},
doi = {10.1145/1160633.1160737},
abstract = {Computer programs able to play different kinds of games (aka bots) is a growing area of interest for the computer game industry as the demand for better skilled computerized opponents increase. We propose a general architecture of a Multi-agent System (Mas) based bot able to play complex board games and show that this solution is able to outperform other bots in two quite different games, namely no-press Diplomacy and Risk. Based on these results, we formulate a hypothesis of the applicability of Mas based bots in the domain of board games and identify the need for future investigations in the area.},
booktitle = {Proceedings of the Fifth International Joint Conference on Autonomous Agents and Multiagent Systems},
pages = {569–576},
numpages = {8},
keywords = {Multiagent system architecture, Board games, RISK, Diplomacy, Artificial intelligence},
location = {Hakodate, Japan},
series = {AAMAS '06}
}


@ARTICLE{8357965,
  author={Baier, Hendrik and Sattaur, Adam and Powley, Edward J. and Devlin, Sam and Rollason, Jeff and Cowling, Peter I.},
  journal={IEEE Transactions on Games}, 
  title={Emulating Human Play in a Leading Mobile Card Game}, 
  year={2019},
  volume={11},
  number={4},
  pages={386-395},
  doi={10.1109/TG.2018.2835764},
  keywords = {Artificial intelligence, digital games, Monte Carlo tree search, neural networks, card games, MCTS algorithm}}

@INPROCEEDINGS{9,
  author={Świechowski, Maciej and Tajmajer, Tomasz and Janusz, Andrzej},
  booktitle={2018 IEEE Conference on Computational Intelligence and Games (CIG)}, 
  title={Improving Hearthstone AI by Combining MCTS and Supervised Learning Algorithms}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/CIG.2018.8490368},
  keywords = {MCTS algorithm, Hearthstone, machine learning, neural networks, heuristic, card games, Artificial intelligence }}

@ARTICLE{10,
  author={Cowling, Peter I. and Devlin, Sam and Powley, Edward J. and Whitehouse, Daniel and Rollason, Jeff},
  journal={IEEE Transactions on Computational Intelligence and AI in Games}, 
  title={Player Preference and Style in a Leading Mobile Card Game}, 
  year={2015},
  volume={7},
  number={3},
  pages={233-242},
  doi={10.1109/TCIAIG.2014.2357174},
  keywords = {Artificial intelligence, data mining, game analytics, Monte Carlo tree search, card games, MCTS algorithm}
}

@article{11,
title = {Automated playtesting in collectible card games using evolutionary algorithms: A case study in hearthstone},
journal = {Knowledge-Based Systems},
volume = {153},
pages = {133-146},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2018.04.030},
url = {https://www.sciencedirect.com/science/article/pii/S0950705118301953},
author = {Pablo García-Sánchez and Alberto Tonda and Antonio M. Mora and Giovanni Squillero and Juan Julián Merelo},
keywords = {Genetic algorithm, Hearthstone, Collectible card games, Artificial intelligence, card games , Genetic algorithm},
abstract = {Collectible card games have been among the most popular and profitable products of the entertainment industry since the early days of Magic: The GatheringTM in the nineties. Digital versions have also appeared, with HearthStone: Heroes of WarCraftTM being one of the most popular. In Hearthstone, every player can play as a hero, from a set of nine, and build his/her deck before the game from a big pool of available cards, including both neutral and hero-specific cards. This kind of games offers several challenges for researchers in artificial intelligence since they involve hidden information, unpredictable behaviour, and a large and rugged search space. Besides, an important part of player engagement in such games is a periodical input of new cards in the system, which mainly opens the door to new strategies for the players. Playtesting is the method used to check the new card sets for possible design flaws, and it is usually performed manually or via exhaustive search; in the case of Hearthstone, such test plays must take into account the chosen hero, with its specific kind of cards. In this paper, we present a novel idea to improve and accelerate the playtesting process, systematically exploring the space of possible decks using an Evolutionary Algorithm (EA). This EA creates HearthStone decks which are then played by an AI versus established human-designed decks. Since the space of possible combinations that are play-tested is huge, search through the space of possible decks has been shortened via a new heuristic mutation operator, which is based on the behaviour of human players modifying their decks. Results show the viability of our method for exploring the space of possible decks and automating the play-testing phase of game design. The resulting decks, that have been examined for balancedness by an expert player, outperform human-made ones when played by the AI; the introduction of the new heuristic operator helps to improve the obtained solutions, and basing the study on the whole set of heroes shows its validity through the whole range of decks.}
}